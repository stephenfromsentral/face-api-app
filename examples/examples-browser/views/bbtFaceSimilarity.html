<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/bbt.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>
<body>
<div id="navbar"></div>
<div class="center-content page-container">
  <div>
    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <div class="row side-by-side">
      <div class="center-content">
        <video id="video1" width="320" height="240" autoplay class="margin"></video>
        <button id="capture1">Capture</button>
        <img id="face1" src="" class="margin"/>
      </div>
      <div class="center-content">
        <input type="file" id="upload2" accept="image/*" class="margin"/>
        <img id="face2" src="" class="margin"/>
      </div>
    </div>
    <div class="row">
      <label for="distance">Distance:</label>
      <input disabled value="-" id="distance" type="text" class="bold">
    </div>
  </div>
</div>

<script>
  const threshold = 0.5;
  let descriptors = { desc1: null, desc2: null };

  function updateResult() {
    if (descriptors.desc1 && descriptors.desc2) {
      const distance = faceapi.utils.round(
        faceapi.euclideanDistance(descriptors.desc1, descriptors.desc2)
      );

      let text = distance;
      let bgColor = '#ffffff';

      if (distance > threshold) {
        text += ' (no match)';
        bgColor = '#ce7575';
      }

      $('#distance').val(text);
      $('#distance').css('background-color', bgColor);
    }
  }

  async function captureImage(which) {
    const video = $(`#video${which}`).get(0);
    const canvas = document.createElement('canvas');

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const context = canvas.getContext('2d');
    context.drawImage(video, 0, 0, canvas.width, canvas.height);
    const imgEl = $(`#face${which}`).get(0);
    imgEl.src = canvas.toDataURL('image/png');
    const input = await faceapi.fetchImage(imgEl.src);

    descriptors[`desc${which}`] = await faceapi.computeFaceDescriptor(input);
    updateResult();

    // Stop the video stream
    const stream = video.srcObject;
    const tracks = stream.getTracks();
    tracks.forEach(track => track.stop());
    video.srcObject = null;
  }

  async function onFileChange(which, file) {
    const imgEl = $(`#face${which}`).get(0);
    const reader = new FileReader();

    reader.onload = async (event) => {
      imgEl.src = event.target.result;
      const input = await faceapi.fetchImage(event.target.result);
      descriptors[`desc${which}`] = await faceapi.computeFaceDescriptor(input);
      updateResult();
    }

    reader.readAsDataURL(file);
  }

  async function startVideo(which) {
    const video = $(`#video${which}`).get(0);
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });

    video.srcObject = stream;
  }

  async function run() {
    await faceapi.loadFaceRecognitionModel('/');
    $('#loader').hide();

    startVideo(1);
  }

  $(document).ready(function() {
    renderNavBar('#navbar', 'bbt_face_similarity');

    $('#capture1').on('click', () => captureImage(1));
    
    $('#upload2').on('change', (event) => {
      const file = event.target.files[0];
      if (file) {
        onFileChange(2, file);
      }
    });

    run();
  });
</script>

</body>
</html>
